{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_3z2AUQOywb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Práctica y entrenamiento ML AD Integrador**"
      ],
      "metadata": {
        "id": "E7jinESLO-Xv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predicción de precios de viviendas:** Utilizando datos históricos de ventas de viviendas, podemos construir un modelo de regresión simple para predecir los precios de viviendas basándose en características como el tamaño, la ubicación y el número de habitaciones. Este modelo puede ser útil para agentes inmobiliarios y compradores para tomar decisiones informadas sobre precios de viviendas."
      ],
      "metadata": {
        "id": "ytrKyTrUPjFS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para desarrollar un ejemplo de predicción de precios de viviendas utilizando un modelo de regresión simple, podemos seguir estos pasos:"
      ],
      "metadata": {
        "id": "_XDDaSJFP0AQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.    Preparación de los datos: Cargar y preparar los datos históricos de ventas de viviendas.\n",
        "2. Exploración de datos: Explorar los datos para comprender su estructura y características.\n",
        "3. Selección de características: Seleccionar las características relevantes que se utilizarán para predecir los precios de las viviendas.\n",
        "4. División de los datos: Dividir los datos en conjuntos de entrenamiento y prueba.\n",
        "5. Entrenamiento del modelo: Entrenar un modelo de regresión utilizando el conjunto de entrenamiento.\n",
        "6. Evaluación del modelo: Evaluar el rendimiento del modelo utilizando el conjunto de prueba.\n",
        "7. Predicción de precios: Utilizar el modelo entrenado para predecir los precios de las viviendas."
      ],
      "metadata": {
        "id": "vfH3xmjZP6K8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cómo implementar estos pasos utilizando scikit-learn en Python"
      ],
      "metadata": {
        "id": "zu30l4nIQxNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Paso 1: Cargar y preparar los datos\n",
        "datos = pd.read_csv('datos_viviendas.csv')\n",
        "\n",
        "# Paso 2: Exploración de datos\n",
        "print(datos.head())\n",
        "print(datos.info())\n",
        "\n",
        "# Paso 3: Selección de características\n",
        "X = datos[['Tamaño', 'Ubicación', 'Num_Habitaciones']]\n",
        "y = datos['Precio']\n",
        "\n",
        "# Paso 4: División de los datos\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Paso 5: Entrenamiento del modelo\n",
        "modelo = LinearRegression()\n",
        "modelo.fit(X_train, y_train)\n",
        "\n",
        "# Paso 6: Evaluación del modelo\n",
        "y_pred = modelo.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"Error cuadrático medio:\", mse)\n",
        "print(\"Coeficiente de determinación (R^2):\", r2)\n",
        "\n",
        "# Paso 7: Predicción de precios\n",
        "nueva_vivienda = [[1500, 'Centro', 3]]\n",
        "precio_predicho = modelo.predict(nueva_vivienda)\n",
        "print(\"Precio predicho para la nueva vivienda:\", precio_predicho)\n"
      ],
      "metadata": {
        "id": "aKV9JOlMQ0Th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este ejemplo:\n",
        "\n",
        "1. Cargamos los datos históricos de ventas de viviendas y seleccionamos las características relevantes (tamaño, ubicación y número de habitaciones).\n",
        "2. Dividimos los datos en conjuntos de entrenamiento y prueba.\n",
        "3. Entrenamos un modelo de regresión lineal utilizando el conjunto de entrenamiento.\n",
        "4. Evaluamos el rendimiento del modelo utilizando el conjunto de prueba.\n",
        "5. Utilizamos el modelo entrenado para predecir el precio de una nueva vivienda."
      ],
      "metadata": {
        "id": "8pxGSK7cQ5Bq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conceptos:\n",
        "\n",
        "**Regresión:**\n",
        "\n",
        "  Explicación de cómo se utiliza para predecir valores numéricos: En la regresión, el objetivo es predecir un valor numérico continuo. Se ajusta una función a los datos de entrenamiento que minimiza la discrepancia entre los valores predichos y los valores reales.\n",
        "\n",
        "**Clasificación:**\n",
        "\n",
        "  Descripción de cómo se utiliza para clasificar datos en categorías: En la clasificación, el objetivo es asignar una etiqueta o categoría a cada instancia de datos. Se ajusta un modelo a los datos de entrenamiento que aprende a distinguir entre diferentes clases o categorías.\n",
        "\n",
        "**Análisis:**\n",
        "\n",
        "***Diferencias entre regresión y clasificación:***\n",
        "\n",
        "  En la regresión, el objetivo es predecir valores numéricos continuos, mientras que en la clasificación, el objetivo es asignar etiquetas categóricas.\n",
        "    \n",
        "  La regresión utiliza funciones de pérdida y métricas de evaluación diferentes a la clasificación debido a la naturaleza de los problemas.\n",
        "    \n",
        "  Los modelos de regresión y clasificación pueden tener arquitecturas y algoritmos diferentes debido a las diferencias en la naturaleza de los datos y las etiquetas.\n",
        "\n",
        "**Importancia de la selección de características y el preprocesamiento de datos:**\n",
        "\n",
        "  La selección de características adecuadas puede mejorar el rendimiento del modelo al eliminar características irrelevantes o redundantes y centrarse en aquellas que son más informativas para el problema.\n",
        "\n",
        "  El preprocesamiento de datos, como la normalización, la estandarización y el manejo de valores atípicos, puede mejorar la capacidad del modelo para generalizar a nuevos datos y reducir el riesgo de sobreajuste."
      ],
      "metadata": {
        "id": "uCeO_d_2RgiQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementación de un modelo de regresión lineal y un modelo de clasificación utilizando el conjunto de datos Iris para clasificación de flores."
      ],
      "metadata": {
        "id": "602g19D8RtVE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Implementación de un modelo de regresión lineal:*"
      ],
      "metadata": {
        "id": "IA4fJQ_nSiT0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Cargar el conjunto de datos Iris\n",
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "X = iris.data[:, :2]  # Solo tomamos las primeras dos características\n",
        "y = iris.target\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear y entrenar el modelo de regresión lineal\n",
        "modelo_regresion = LinearRegression()\n",
        "modelo_regresion.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred_regresion = modelo_regresion.predict(X_test)\n",
        "\n",
        "# Calcular el error cuadrático medio\n",
        "mse_regresion = mean_squared_error(y_test, y_pred_regresion)\n",
        "print(\"Error cuadrático medio (Regresión lineal):\", mse_regresion)\n"
      ],
      "metadata": {
        "id": "PetF_5U4SoD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Implementación de un modelo de clasificación:*"
      ],
      "metadata": {
        "id": "F4cP7ZYiSsR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Crear y entrenar el modelo de clasificación\n",
        "modelo_clasificacion = LogisticRegression()\n",
        "modelo_clasificacion.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred_clasificacion = modelo_clasificacion.predict(X_test)\n",
        "\n",
        "# Calcular la precisión del modelo\n",
        "precision_clasificacion = accuracy_score(y_test, y_pred_clasificacion)\n",
        "print(\"Precisión (Modelo de clasificación):\", precision_clasificacion)\n"
      ],
      "metadata": {
        "id": "msmz_E4FSzZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En Estos ejemplos ilustran cómo implementar modelos de regresión y clasificación utilizando scikit-learn en Python, y cómo evaluar el rendimiento de estos modelos utilizando métricas como el error cuadrático medio en el caso de la regresión y la precisión en el caso de la clasificación."
      ],
      "metadata": {
        "id": "Jzid6fHqS4x8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Métricas de evaluación de modelos:**"
      ],
      "metadata": {
        "id": "GdWMlNWOTIHG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 1. **MSE (Error Cuadrático Medio) para regresión:** Es una métrica comúnmente utilizada para evaluar la calidad de un modelo de regresión. Calcula el promedio de los errores al cuadrado entre las predicciones del modelo y los valores reales. Un MSE más bajo indica un mejor ajuste del modelo a los datos.\n",
        "\n",
        " 2. **Precisión y Recall para clasificación:** Son métricas utilizadas para evaluar la calidad de un modelo de clasificación. La precisión es la proporción de instancias clasificadas correctamente como positivas entre todas las instancias clasificadas como positivas por el modelo. El recall es la proporción de instancias clasificadas correctamente como positivas entre todas las instancias positivas reales. Ambas métricas son importantes y se deben considerar en conjunto, ya que una alta precisión puede ser contrarrestada por un bajo recall y viceversa."
      ],
      "metadata": {
        "id": "JBrGVNryTKWA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importancia de la validación cruzada para evaluar el rendimiento del modelo:**\n",
        "\n",
        "La validación cruzada es una técnica importante utilizada para evaluar el rendimiento de un modelo de Machine Learning. Consiste en dividir el conjunto de datos en múltiples subconjuntos de entrenamiento y prueba, ajustar el modelo en cada subconjunto de entrenamiento y evaluar su rendimiento en el subconjunto de prueba. Esto permite obtener estimaciones más confiables del rendimiento del modelo y reducir el riesgo de sobreajuste."
      ],
      "metadata": {
        "id": "hp5vPT0UTjx7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Ejemplos que ilustran cómo aplicar el aprendizaje automático y el análisis exploratorio de datos utilizando los conjuntos de datos de Iris y Vinos.\n",
        "\n",
        "*Cómo cargar, explorar, visualizar y modelar datos utilizando scikit-learn y pandas en Python. Estos son pasos fundamentales en el proceso de análisis de datos y aprendizaje automático.*\n"
      ],
      "metadata": {
        "id": "n-BrqqtSU2Da"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplo de Clasificación con el Conjunto de Datos Iris:"
      ],
      "metadata": {
        "id": "hq4vWwnPT1jH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Este ejemplo utiliza el algoritmo **RandomForest** para clasificar las flores del conjunto de datos Iris en una de las tres especies diferentes.*"
      ],
      "metadata": {
        "id": "l91LSPl_UA2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clasificación con el Conjunto de Datos Iris:\n",
        "\n",
        "  * Cargar los datos y Dividirlos:\n",
        "      Se cargan los datos del conjunto de datos Iris utilizando la función load_iris() de scikit-learn.\n",
        "      Los datos se dividen en conjuntos de entrenamiento y prueba utilizando la función train_test_split() de scikit-learn. En este caso, el 80% de los datos se utilizan para entrenamiento y el 20% para pruebas.\n",
        "\n",
        "  * Entrenar el Modelo:\n",
        "\n",
        "    Se crea un clasificador RandomForest utilizando la clase RandomForestClassifier() de scikit-learn.\n",
        "    El clasificador se entrena en los datos de entrenamiento utilizando el método fit().\n",
        "\n",
        "  * Realizar Predicciones y Evaluar el Modelo:\n",
        "\n",
        "      Se utilizan los datos de prueba para hacer predicciones utilizando el método predict() del clasificador entrenado.\n",
        "      Se calcula la precisión del modelo comparando las predicciones con las etiquetas reales utilizando la métrica accuracy_score() de scikit-learn."
      ],
      "metadata": {
        "id": "KXtgjObqVLEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Cargar el conjunto de datos Iris\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear y entrenar un clasificador RandomForest\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calcular la precisión del modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Precisión del modelo:\", accuracy)\n"
      ],
      "metadata": {
        "id": "K3OzY_xIT4g8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplo de Análisis Exploratorio de Datos con el Conjunto de Datos de Vinos:"
      ],
      "metadata": {
        "id": "D5Y3wzQnUOBy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este ejemplo realiza un análisis exploratorio de datos en el conjunto de datos de vinos, incluyendo información sobre las características y la distribución de los datos, así como visualizaciones de la relación entre las características y la variable objetivo (tipo de vino)."
      ],
      "metadata": {
        "id": "Kk-kHOIZUXNc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Análisis Exploratorio de Datos con el Conjunto de Datos de Vinos:\n",
        "\n",
        "  * Cargar y Explorar los Datos:\n",
        "      Se carga el conjunto de datos de vinos utilizando la función load_wine() de scikit-learn.\n",
        "\n",
        "      Se crea un DataFrame de Pandas con los datos y se imprime información básica sobre el conjunto de datos utilizando los métodos info() y describe().\n",
        "\n",
        "  * Visualización de las Características:\n",
        "      Se crea una figura de matplotlib con subtramas para cada característica del conjunto de datos.\n",
        "\n",
        "      Se utiliza la biblioteca seaborn para trazar histogramas de las características y visualizar su distribución.\n",
        "\n",
        "  * Visualización de la Relación entre Características y la Variable Objetivo:\n",
        "  \n",
        "      Se crea otra figura de matplotlib con subtramas para cada característica del conjunto de datos.\n",
        "\n",
        "      Se utiliza seaborn para trazar diagramas de caja que muestran la distribución de cada característica según la variable objetivo (tipo de vino)."
      ],
      "metadata": {
        "id": "9WB2NoTaV7E1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_wine\n",
        "\n",
        "# Cargar el conjunto de datos de vinos\n",
        "wine = load_wine()\n",
        "\n",
        "# Crear un DataFrame de Pandas\n",
        "df = pd.DataFrame(data=wine.data, columns=wine.feature_names)\n",
        "df['target'] = wine.target\n",
        "\n",
        "# Exploración inicial del conjunto de datos\n",
        "print(\"Información del conjunto de datos:\")\n",
        "print(df.info())\n",
        "print(\"\\nDescripción del conjunto de datos:\")\n",
        "print(df.describe())\n",
        "\n",
        "# Visualización de las características\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i, feature in enumerate(wine.feature_names):\n",
        "    plt.subplot(2, 6, i + 1)\n",
        "    sns.histplot(df[feature], bins=20, kde=True)\n",
        "    plt.title(feature)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualización de la relación entre las características y la variable objetivo\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i, feature in enumerate(wine.feature_names):\n",
        "    plt.subplot(2, 6, i + 1)\n",
        "    sns.boxplot(x='target', y=feature, data=df)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Nj0q2BXWUby3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "Ejemplos prácticos de análisis de datos y machine learning utilizando el conjunto de datos Iris, enfocados a proyectos reales\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "NK69-Jn3WpGI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo 1: Clasificación de Especies de Flores con K-Nearest Neighbors (KNN)**\n",
        "\n",
        "Este ejemplo muestra cómo utilizar el algoritmo KNN para clasificar las especies de flores del conjunto de datos Iris."
      ],
      "metadata": {
        "id": "_62ApYTJW2_l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clasificación con KNN\n",
        "\n",
        "  * Cargar datos: Utiliza load_iris() para cargar los datos.\n",
        "  * Dividir datos: train_test_split() divide los datos en conjuntos de entrenamiento y prueba.\n",
        "  * Entrenar modelo: KNeighborsClassifier() crea un clasificador KNN con n_neighbors=3.\n",
        "  * Predecir y evaluar: accuracy_score y classification_report evalúan la precisión y el rendimiento del modelo. confusion_matrix y heatmap visualizan los resultados."
      ],
      "metadata": {
        "id": "5Cn21l9rX3vB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Cargar el conjunto de datos Iris\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear y entrenar el modelo KNN\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Evaluar el modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Precisión del modelo KNN:\", accuracy)\n",
        "print(\"Reporte de clasificación:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Mostrar la matriz de confusión\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "G5aninCLW7dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo 2: Regresión Lineal para Predicción de Longitud de Pétalo**\n",
        "\n",
        "Este ejemplo muestra cómo utilizar la regresión lineal para predecir la longitud del pétalo de las flores en función de otras características."
      ],
      "metadata": {
        "id": "H1Gwfcj0XA_H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regresión Lineal\n",
        "\n",
        "  * Seleccionar características: Se utilizan las dos primeras características para predecir la longitud del pétalo.\n",
        "  * Dividir datos: train_test_split() divide los datos en conjuntos de entrenamiento y prueba.\n",
        "  * Entrenar modelo: LinearRegression() crea un modelo de regresión lineal.\n",
        "  * Predecir y evaluar: mean_squared_error calcula el error cuadrático medio. plt.scatter visualiza los resultados."
      ],
      "metadata": {
        "id": "gL0m8v4lYKJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Seleccionar las características (Sepal Length y Sepal Width) y la variable objetivo (Petal Length)\n",
        "X = iris.data[:, :2]\n",
        "y = iris.data[:, 2]\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear y entrenar el modelo de regresión lineal\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred = lin_reg.predict(X_test)\n",
        "\n",
        "# Evaluar el modelo\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Error Cuadrático Medio (MSE):\", mse)\n",
        "\n",
        "# Visualizar los resultados\n",
        "plt.scatter(X_test[:, 0], y_test, color='blue', label='Actual')\n",
        "plt.scatter(X_test[:, 0], y_pred, color='red', label='Predicho')\n",
        "plt.xlabel('Longitud del Sépalo')\n",
        "plt.ylabel('Longitud del Pétalo')\n",
        "plt.title('Regresión Lineal - Predicción de Longitud del Pétalo')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "c6viUH-0XHm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo 3: Análisis de Componentes Principales (PCA) para Reducción de Dimensionalidad**\n",
        "\n",
        "Este ejemplo muestra cómo utilizar PCA para reducir la dimensionalidad del conjunto de datos Iris y visualizar las características más importantes."
      ],
      "metadata": {
        "id": "XkjLnwJKXNKM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA\n",
        "\n",
        "  * Reducir dimensionalidad: PCA(n_components=2) reduce los datos a dos componentes principales.\n",
        "  * Crear DataFrame: Un DataFrame de Pandas se utiliza para almacenar los componentes principales y las etiquetas.\n",
        "  * Visualizar componentes: sns.scatterplot visualiza los componentes principales en un gráfico de dispersión."
      ],
      "metadata": {
        "id": "wFdkexvRYZzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Reducir la dimensionalidad a 2 componentes principales\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X)\n",
        "\n",
        "# Crear un DataFrame con los componentes principales y las etiquetas\n",
        "df_pca = pd.DataFrame(X_pca, columns=['Componente 1', 'Componente 2'])\n",
        "df_pca['Especie'] = y\n",
        "\n",
        "# Visualizar los componentes principales\n",
        "sns.scatterplot(data=df_pca, x='Componente 1', y='Componente 2', hue='Especie', palette='Set1')\n",
        "plt.title('Análisis de Componentes Principales (PCA)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "O03uOGuHXTCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo 4: Validación Cruzada para Evaluar Modelos**\n",
        "\n",
        "Este ejemplo muestra cómo utilizar la validación cruzada para evaluar el rendimiento de un modelo de clasificación en el conjunto de datos Iris."
      ],
      "metadata": {
        "id": "y3JulQPaXXMR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validación Cruzada\n",
        "\n",
        "  * Crear modelo: KNeighborsClassifier() crea un clasificador KNN.\n",
        "  * Evaluar modelo: cross_val_score evalúa el modelo utilizando validación cruzada con 5 particiones (cv=5)."
      ],
      "metadata": {
        "id": "l-mLVr_eYqGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Crear el modelo KNN\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "# Evaluar el modelo utilizando validación cruzada\n",
        "scores = cross_val_score(knn, X, y, cv=5)\n",
        "print(\"Precisión promedio con validación cruzada:\", scores.mean())\n"
      ],
      "metadata": {
        "id": "647NzoPlXjmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo 5: Clasificación con Support Vector Machine (SVM)**\n",
        "\n",
        "Este ejemplo muestra cómo utilizar un clasificador SVM para clasificar las especies de flores del conjunto de datos Iris."
      ],
      "metadata": {
        "id": "LJ2n5JZbY5NX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clasificación con SVM\n",
        "\n",
        "  * Crear y entrenar el modelo: SVC(kernel='linear', random_state=42) crea un clasificador SVM con un kernel lineal.\n",
        "  * Predecir y evaluar: accuracy_score y classification_report se utilizan para evaluar el rendimiento del modelo. confusion_matrix y heatmap visualizan los resultados."
      ],
      "metadata": {
        "id": "52eMoZbXZpjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Cargar el conjunto de datos Iris\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear y entrenar el modelo SVM\n",
        "svm = SVC(kernel='linear', random_state=42)\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred = svm.predict(X_test)\n",
        "\n",
        "# Evaluar el modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Precisión del modelo SVM:\", accuracy)\n",
        "print(\"Reporte de clasificación:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Mostrar la matriz de confusión\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rOOpGalSZDtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo 6: K-Means Clustering**\n",
        "\n",
        "Este ejemplo muestra cómo utilizar el algoritmo K-Means para realizar clustering en el conjunto de datos Iris."
      ],
      "metadata": {
        "id": "zwijlMlmZJJr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Means Clustering\n",
        "\n",
        "  * Estandarizar las características: StandardScaler se utiliza para escalar las características.\n",
        "  * Aplicar K-Means: KMeans(n_clusters=3, random_state=42) aplica el algoritmo K-Means con 3 clusters.\n",
        "  * Visualizar clusters: Se añaden etiquetas de cluster al DataFrame y se visualizan utilizando sns.scatterplot."
      ],
      "metadata": {
        "id": "DMdhO-UVZ1we"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Estandarizar las características\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Aplicar K-Means\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "kmeans.fit(X_scaled)\n",
        "\n",
        "# Añadir las etiquetas de cluster al DataFrame original\n",
        "df = pd.DataFrame(data=X, columns=iris.feature_names)\n",
        "df['Cluster'] = kmeans.labels_\n",
        "\n",
        "# Visualizar los clusters\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(data=df, x='sepal length (cm)', y='sepal width (cm)', hue='Cluster', palette='Set1')\n",
        "plt.title('Clusters de K-Means')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hFEpz2rSZNuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo 7: Regresión Logística**\n",
        "\n",
        "Este ejemplo muestra cómo utilizar la regresión logística para clasificar las especies de flores del conjunto de datos Iris."
      ],
      "metadata": {
        "id": "_0JealDDZSqs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regresión Logística\n",
        "\n",
        "  * Crear y entrenar el modelo: LogisticRegression(max_iter=200, random_state=42) crea un modelo de regresión logística.\n",
        "  * Predecir y evaluar: accuracy_score y classification_report se utilizan para evaluar el rendimiento del modelo. confusion_matrix y heatmap visualizan los resultados."
      ],
      "metadata": {
        "id": "T1JKxygyaADk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Crear y entrenar el modelo de regresión logística\n",
        "log_reg = LogisticRegression(max_iter=200, random_state=42)\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred = log_reg.predict(X_test)\n",
        "\n",
        "# Evaluar el modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Precisión del modelo de Regresión Logística:\", accuracy)\n",
        "print(\"Reporte de clasificación:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Mostrar la matriz de confusión\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kKgLMViPZWyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo 8: Árboles de Decisión**\n",
        "\n",
        "Este ejemplo muestra cómo utilizar un árbol de decisión para clasificar las especies de flores del conjunto de datos Iris."
      ],
      "metadata": {
        "id": "0eSUBS6JZaxh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Árboles de Decisión\n",
        "\n",
        "  * Crear y entrenar el modelo: DecisionTreeClassifier(random_state=42) crea un modelo de árbol de decisión.\n",
        "  * Predecir y evaluar: accuracy_score y classification_report se utilizan para evaluar el rendimiento del modelo. plot_tree se utiliza para visualizar el árbol de decisión."
      ],
      "metadata": {
        "id": "2yhA30UBaKpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import plot_tree\n",
        "\n",
        "# Crear y entrenar el modelo de árbol de decisión\n",
        "tree_clf = DecisionTreeClassifier(random_state=42)\n",
        "tree_clf.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred = tree_clf.predict(X_test)\n",
        "\n",
        "# Evaluar el modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Precisión del modelo de Árbol de Decisión:\", accuracy)\n",
        "print(\"Reporte de clasificación:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Visualizar el árbol de decisión\n",
        "plt.figure(figsize=(20, 10))\n",
        "plot_tree(tree_clf, filled=True, feature_names=iris.feature_names, class_names=iris.target_names)\n",
        "plt.title('Árbol de Decisión')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "J46316PxZfIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "**Ejemplos prácticos de análisis de datos y machine learning utilizando el conjunto de datos de vinos (load_wine) de scikit-learn, enfocados en proyectos reales.**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BKN2ExJtaZAX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo 1: Clasificación con K-Nearest Neighbors (KNN)**\n",
        "\n",
        "Este ejemplo muestra cómo utilizar el algoritmo KNN para clasificar los tipos de vino en el conjunto de datos de vinos."
      ],
      "metadata": {
        "id": "4WkDZU60ambT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clasificación con KNN\n",
        "\n",
        "  * Crear y entrenar el modelo: KNeighborsClassifier(n_neighbors=3) crea un clasificador KNN con n_neighbors=3.\n",
        "  * Predecir y evaluar: accuracy_score, classification_report y confusion_matrix se utilizan para evaluar y visualizar el rendimiento del modelo."
      ],
      "metadata": {
        "id": "U4zFzLmLbuhd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Cargar el conjunto de datos de vinos\n",
        "wine = load_wine()\n",
        "X = wine.data\n",
        "y = wine.target\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear y entrenar el modelo KNN\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Evaluar el modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Precisión del modelo KNN:\", accuracy)\n",
        "print(\"Reporte de clasificación:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Mostrar la matriz de confusión\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Dwo_ftj-atG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo 2: Regresión Logística**\n",
        "\n",
        "Este ejemplo muestra cómo utilizar la regresión logística para clasificar los tipos de vino."
      ],
      "metadata": {
        "id": "vi96t2R1axWS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regresión Logística\n",
        "\n",
        "  * Crear y entrenar el modelo: LogisticRegression(max_iter=200, random_state=42) crea un modelo de regresión logística con un máximo de 200 iteraciones.\n",
        "  * Predecir y evaluar: accuracy_score, classification_report y confusion_matrix se utilizan para evaluar y visualizar el rendimiento del modelo."
      ],
      "metadata": {
        "id": "saCop83xb8vV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Crear y entrenar el modelo de regresión logística\n",
        "log_reg = LogisticRegression(max_iter=200, random_state=42)\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred = log_reg.predict(X_test)\n",
        "\n",
        "# Evaluar el modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Precisión del modelo de Regresión Logística:\", accuracy)\n",
        "print(\"Reporte de clasificación:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Mostrar la matriz de confusión\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KZyzbsyOa1Eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo 3: Análisis de Componentes Principales (PCA)**\n",
        "\n",
        "Este ejemplo muestra cómo utilizar PCA para reducir la dimensionalidad del conjunto de datos de vinos y visualizar las características más importantes."
      ],
      "metadata": {
        "id": "AUw3C5V2a7x1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA\n",
        "\n",
        "  * Reducir la dimensionalidad: PCA(n_components=2) reduce los datos a dos componentes principales.\n",
        "  * Visualizar componentes: sns.scatterplot visualiza los componentes principales en un gráfico de dispersión."
      ],
      "metadata": {
        "id": "3gpJs5fUcK5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Reducir la dimensionalidad a 2 componentes principales\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X)\n",
        "\n",
        "# Crear un DataFrame con los componentes principales y las etiquetas\n",
        "df_pca = pd.DataFrame(X_pca, columns=['Componente 1', 'Componente 2'])\n",
        "df_pca['Clase de Vino'] = y\n",
        "\n",
        "# Visualizar los componentes principales\n",
        "sns.scatterplot(data=df_pca, x='Componente 1', y='Componente 2', hue='Clase de Vino', palette='Set1')\n",
        "plt.title('Análisis de Componentes Principales (PCA)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "V80JhD6Ra_ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo 4: Árboles de Decisión**\n",
        "\n",
        "Este ejemplo muestra cómo utilizar un árbol de decisión para clasificar los tipos de vino."
      ],
      "metadata": {
        "id": "4Yag9iYhbEEE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Árboles de Decisión\n",
        "\n",
        "  * Crear y entrenar el modelo: DecisionTreeClassifier(random_state=42) crea un modelo de árbol de decisión.\n",
        "  * Predecir y evaluar: accuracy_score, classification_report y confusion_matrix se utilizan para evaluar y visualizar el rendimiento del modelo. plot_tree visualiza la estructura del árbol de decisión."
      ],
      "metadata": {
        "id": "6Eq1Xg_acXSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import plot_tree\n",
        "\n",
        "# Crear y entrenar el modelo de árbol de decisión\n",
        "tree_clf = DecisionTreeClassifier(random_state=42)\n",
        "tree_clf.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred = tree_clf.predict(X_test)\n",
        "\n",
        "# Evaluar el modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Precisión del modelo de Árbol de Decisión:\", accuracy)\n",
        "print(\"Reporte de clasificación:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Visualizar el árbol de decisión\n",
        "plt.figure(figsize=(20, 10))\n",
        "plot_tree(tree_clf, filled=True, feature_names=wine.feature_names, class_names=wine.target_names)\n",
        "plt.title('Árbol de Decisión')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6tTFRDcwbJmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo 5: Random Forest**\n",
        "\n",
        "Este ejemplo muestra cómo utilizar un bosque aleatorio (Random Forest) para clasificar los tipos de vino."
      ],
      "metadata": {
        "id": "JUZ40HcNbM0M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest\n",
        "\n",
        "  * Crear y entrenar el modelo: RandomForestClassifier(n_estimators=100, random_state=42) crea un modelo de bosque aleatorio con 100 árboles.\n",
        "  * Predecir y evaluar: accuracy_score, classification_report y confusion_matrix se utilizan para evaluar y visualizar el rendimiento del modelo."
      ],
      "metadata": {
        "id": "LKcL68LeckVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Crear y entrenar el modelo de Random Forest\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred = rf_clf.predict(X_test)\n",
        "\n",
        "# Evaluar el modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Precisión del modelo de Random Forest:\", accuracy)\n",
        "print(\"Reporte de clasificación:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Mostrar la matriz de confusión\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Jr6GH1vobQup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "CONCEPTOS TEORICOS\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_FYd88dlcvd1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clasificación con K-Nearest Neighbors (KNN)\n",
        "\n",
        "Conceptos Clave:\n",
        "\n",
        "  * K-Nearest Neighbors (KNN) es un algoritmo de clasificación supervisado que asigna una clase a un nuevo punto basándose en las clases de sus k vecinos más cercanos.\n",
        "  * Distancia: Se utiliza una métrica de distancia (comúnmente la distancia Euclidiana) para determinar qué puntos son los más cercanos.\n",
        "  * Valor de k: El número de vecinos considerados (k) afecta el resultado; un k pequeño puede hacer que el modelo sea sensible al ruido, mientras que un k grande puede suavizar demasiado la clasificación."
      ],
      "metadata": {
        "id": "8_173mtPdGPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Cargar el conjunto de datos de vinos\n",
        "wine = load_wine()\n",
        "X = wine.data\n",
        "y = wine.target\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear y entrenar el modelo KNN\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Evaluar el modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Precisión del modelo KNN:\", accuracy)\n",
        "print(\"Reporte de clasificación:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Mostrar la matriz de confusión\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "XLAJ87hEdQUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regresión Logística\n",
        "\n",
        "Conceptos Clave:\n",
        "\n",
        "  * Regresión Logística es un algoritmo de clasificación supervisado utilizado para modelar la probabilidad de una clase binaria. Puede extenderse a problemas de clasificación multiclase.\n",
        "  * Función Sigmoide: La regresión logística utiliza la función sigmoide para convertir una predicción lineal en una probabilidad.\n",
        "  * Máxima Verosimilitud: El modelo se ajusta a los datos maximizando la función de verosimilitud, es decir, la probabilidad de observar los datos dados los parámetros del modelo."
      ],
      "metadata": {
        "id": "JJuDnetKdY1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Crear y entrenar el modelo de regresión logística\n",
        "log_reg = LogisticRegression(max_iter=200, random_state=42)\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred = log_reg.predict(X_test)\n",
        "\n",
        "# Evaluar el modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Precisión del modelo de Regresión Logística:\", accuracy)\n",
        "print(\"Reporte de clasificación:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Mostrar la matriz de confusión\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "A_jWrebWdiQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Análisis de Componentes Principales (PCA)\n",
        "\n",
        "Conceptos Clave:\n",
        "\n",
        "  * Análisis de Componentes Principales (PCA) es una técnica de reducción de dimensionalidad que transforma los datos a un nuevo espacio de características, maximizando la varianza explicada por cada componente.\n",
        "  * Varianza Explicada: Cada componente principal captura un porcentaje de la varianza total de los datos, ayudando a identificar las características más importantes.\n",
        "  * Covarianza y Autovalores: PCA se basa en la descomposición de la matriz de covarianza de los datos, utilizando los autovalores y autovectores para proyectar los datos en el nuevo espacio."
      ],
      "metadata": {
        "id": "1T5K6_fmdm9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Reducir la dimensionalidad a 2 componentes principales\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X)\n",
        "\n",
        "# Crear un DataFrame con los componentes principales y las etiquetas\n",
        "df_pca = pd.DataFrame(X_pca, columns=['Componente 1', 'Componente 2'])\n",
        "df_pca['Clase de Vino'] = y\n",
        "\n",
        "# Visualizar los componentes principales\n",
        "sns.scatterplot(data=df_pca, x='Componente 1', y='Componente 2', hue='Clase de Vino', palette='Set1')\n",
        "plt.title('Análisis de Componentes Principales (PCA)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eAB92AUsduvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Árboles de Decisión\n",
        "\n",
        "Conceptos Clave:\n",
        "\n",
        "  * Árboles de Decisión son algoritmos de clasificación y regresión que utilizan una estructura de árbol para tomar decisiones basadas en las características de los datos.\n",
        "  * Nodos y Hojas: Cada nodo representa una característica, cada rama una decisión basada en esa característica y cada hoja una predicción.\n",
        "  * Gini y Entropía: Son criterios de medida de la impureza de un nodo, utilizados para decidir las divisiones en los nodos."
      ],
      "metadata": {
        "id": "ixVC7a0EdzPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import plot_tree\n",
        "\n",
        "# Crear y entrenar el modelo de árbol de decisión\n",
        "tree_clf = DecisionTreeClassifier(random_state=42)\n",
        "tree_clf.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred = tree_clf.predict(X_test)\n",
        "\n",
        "# Evaluar el modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Precisión del modelo de Árbol de Decisión:\", accuracy)\n",
        "print(\"Reporte de clasificación:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Visualizar el árbol de decisión\n",
        "plt.figure(figsize=(20, 10))\n",
        "plot_tree(tree_clf, filled=True, feature_names=wine.feature_names, class_names=wine.target_names)\n",
        "plt.title('Árbol de Decisión')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "e43xM2rRd6xG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest\n",
        "\n",
        "Conceptos Clave:\n",
        "\n",
        "  * Random Forest es un conjunto de árboles de decisión, donde cada árbol se entrena con un subconjunto aleatorio de los datos y características.\n",
        "  * Bagging (Bootstrap Aggregating): Cada árbol se entrena con una muestra aleatoria con reemplazo de los datos de entrenamiento.\n",
        "  * Promediar Predicciones: Las predicciones de los árboles individuales se promedian (regresión) o se toma la mayoría de votos (clasificación)."
      ],
      "metadata": {
        "id": "dxXx52Fid_qF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Crear y entrenar el modelo de Random Forest\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred = rf_clf.predict(X_test)\n",
        "\n",
        "# Evaluar el modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Precisión del modelo de Random Forest:\", accuracy)\n",
        "print(\"Reporte de clasificación:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Mostrar la matriz de confusión\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "I6x1Wt_FeH3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Ejemplos de Aplicación en Proyectos Reales**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**Clasificación de Calidad de Vino**\n",
        "\n",
        "\n",
        "**Contexto:** Clasificar la calidad del vino en función de sus características químicas.\n",
        "\n",
        "  **Característica:** Atributos químicos como acidez, azúcar residual, pH, etc.\n",
        "\n",
        "  **Etiqueta:** Clase de calidad (e.g., baja, media, alta).\n",
        "\n",
        "**Predicción de Precios de Vino**\n",
        "\n",
        " **Contexto:** Predecir el precio de una botella de vino en función de sus características químicas y sensoriales.\n",
        "\n",
        " **Característica:** Atributos como año de cosecha, región de producción, Puntuación de críticos.\n",
        " **Etiqueta:** Precio de la botella."
      ],
      "metadata": {
        "id": "_wJxSfEReRZ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejemplo práctico utilizando Python y el conjunto de datos de vinos para realizar un análisis exploratorio y construir un modelo de clasificación utilizando el algoritmo de Árbol de Decisión:"
      ],
      "metadata": {
        "id": "XBAG6oWsf-7Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Este ejemplo proporciona una introducción práctica al análisis de datos y machine learning utilizando Python y el conjunto de datos de vinos.*"
      ],
      "metadata": {
        "id": "NH2PFUoLgOa3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este ejemplo, primero cargamos el conjunto de datos de vinos y lo dividimos en conjuntos de entrenamiento y prueba. Luego creamos un modelo de Árbol de Decisión, lo entrenamos con los datos de entrenamiento y realizamos predicciones en el conjunto de prueba. Finalmente, evaluamos el rendimiento del modelo utilizando métricas como precisión, y visualizamos la matriz de confusión para entender mejor los resultados."
      ],
      "metadata": {
        "id": "iz1kIC8CgWL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Cargar el conjunto de datos de vinos\n",
        "wine = load_wine()\n",
        "X = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
        "y = pd.Series(wine.target, name='target')\n",
        "\n",
        "# Dividir los datos en conjunto de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear y entrenar el modelo de Árbol de Decisión\n",
        "tree_clf = DecisionTreeClassifier(random_state=42)\n",
        "tree_clf.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred = tree_clf.predict(X_test)\n",
        "\n",
        "# Evaluar el modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Precisión del modelo de Árbol de Decisión:\", accuracy)\n",
        "print(\"Reporte de clasificación:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Mostrar la matriz de confusión\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KfhyOETlgFn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> *Recopilacion: William Burbano Lima (Ejecutor Técnico Bootcamp Analisis de Datos Nivel Integrador Talento Tech MINTIC COLOMBIA)*\n",
        "\n"
      ],
      "metadata": {
        "id": "sIUTwQrzgbGi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cc1GEY3EhIcd"
      }
    }
  ]
}